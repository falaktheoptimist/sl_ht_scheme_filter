{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from ast import literal_eval\n",
    "from typing import List, Dict\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain.llms import Clarifai\n",
    "from langchain import PromptTemplate\n",
    "from langchain.document_loaders import BSHTMLLoader\n",
    "from langchain.document_loaders import UnstructuredURLLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TYPES_FILE_PATH = \"./fields.json\"\n",
    "GUJARAT_SCHEMES_INDEX_PATH = \"./gujarat_scheme_index.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_model():\n",
    "    PAT = \"2e47a12333004eafbd898b21e5bc94cf\"\n",
    "    USER_ID = \"openai\"\n",
    "    APP_ID = \"chat-completion\"\n",
    "    MODEL_ID = \"GPT-4\"\n",
    "    llm = Clarifai(pat=PAT, user_id=USER_ID, app_id=APP_ID, model_id=MODEL_ID)\n",
    "    return llm\n",
    "\n",
    "\n",
    "llm = get_text_model()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils for scraping links"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tamil Nadu Schemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn_scheme_urls = []\n",
    "beneficiary_main_urls = [\n",
    "    f\"https://www.tn.gov.in/scheme/beneficiary_wise/{x}\" for x in [2, 6, 8, 14, 18]\n",
    "]\n",
    "for url in beneficiary_main_urls:\n",
    "    page = requests.get(url, verify=False)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    divs = soup.find_all(\"div\", class_=\"scheme_list\")\n",
    "    tn_scheme_urls.extend(\n",
    "        [div.find(\"a\")[\"href\"] for div in divs]\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gujarat Schemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the page required js to load link\n",
    "# saved loaded page locally to find links\n",
    "path = Path(GUJARAT_SCHEMES_INDEX_PATH)\n",
    "html_content = path.read_text()\n",
    "soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "scheme_div = soup.find(\"div\", id=\"result\")\n",
    "gj_scheme_urls = [tag[\"href\"] for tag in scheme_div.find_all(\"a\")]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils for Processing Scheme Web Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_web_page(scheme_link: str):\n",
    "    loader = UnstructuredURLLoader([scheme_link], ssl_verify=False)\n",
    "    document = loader.load()[0]\n",
    "    # remove lines without any text\n",
    "    lines = document.page_content.split(\"\\n\")\n",
    "    filtered_lines = [line for line in lines if line.strip()]\n",
    "    return \"\\n\".join(filtered_lines)\n",
    "    \n",
    "\n",
    "def get_existing_types():\n",
    "    with open(TYPES_FILE_PATH, \"r\") as f:\n",
    "        field_to_types = json.load(f)\n",
    "    return field_to_types\n",
    "\n",
    "\n",
    "def get_types_suggestions(web_page_text: str, field_to_types: Dict[str, List[str]]):\n",
    "    prompt_template = \"\"\"You are a legal expert who is tasked with analyzing text from a\n",
    "government scheme. Each scheme can be classified into some category for different fields\n",
    "like gender, occupation, category and beneficiary. Analyze the provided text to \n",
    "determine if any new types are required for different fields. The current types are:\n",
    "    \n",
    "{current_types}\n",
    "\n",
    "Text to Analyze: {text}\n",
    "\n",
    "Instructions:\n",
    "* For each category, check if the text can be categorized using existing types.\n",
    "* If the text cannot be categorized, suggest a new type for the text else give an empty \n",
    "suggestion.\n",
    "\n",
    "Output Format: \n",
    "* The output should be a json object containing suggestions for each field.\n",
    "* Ensure all fields are present in the json. If the field does not require new types,\n",
    "return an empty list.\n",
    "* json object must wrapped around by \"<json> </json>\" tags\n",
    "Example: <json>{{\"beneficiary\": [\"value_1\", \"value_2\", ...], \"gender\": [\"value_1\", \"value_2\", ...], \"occupation\": [\"value_1\", \"value_2\", ...], \"category\": [\"value_1\", \"value_2\", ...]}}</json>\n",
    "\n",
    "Response:\"\"\"\n",
    "    prompt = PromptTemplate(template=prompt_template, input_variables=[\"text\", \"current_types\"])\n",
    "    response = llm(prompt.format(text=web_page_text, current_types=field_to_types))\n",
    "    json_pattern = f\"(?<=<json>).*(?=</json>)\"\n",
    "    dict_string = re.search(json_pattern, response).group()\n",
    "    types_suggestions = literal_eval(dict_string)\n",
    "    return types_suggestions\n",
    "    \n",
    "\n",
    "def update_existing_types(field_to_new_types: Dict[str, List[str]]):\n",
    "    with open(TYPES_FILE_PATH, \"r+\") as f:\n",
    "        json_string = f.read()\n",
    "        field_to_types = json.loads(json_string)\n",
    "        for field, types in field_to_new_types.items():\n",
    "            field_to_types[field].extend(types)\n",
    "        f.seek(0)\n",
    "        f.truncate()\n",
    "        f.write(json.dumps(field_to_types))\n",
    "    return field_to_types\n",
    "\n",
    "\n",
    "def get_scheme_details(web_page_text: str, field_to_types: Dict[str, List[str]]):\n",
    "    prompt_template = \"\"\"You are a legal expert who is tasked with analyzing text from a\n",
    "government scheme. Each scheme can be classified into some category for different fields\n",
    "like gender, occupation, category and beneficiary. Analyze the provided text to extract \n",
    "eligibility criteria for each of the fields. The eligible options for each field are:\n",
    "\n",
    "{current_types}\n",
    "\n",
    "Text to Analyze: {text}\n",
    "\n",
    "Output Format: Only return a json object wrapped around by \"<json> </json>\" tags\n",
    "Example: <json>{{\"beneficiary\": [\"value_1\", \"value_2\", ...], \"gender\": [\"value_1\", \"value_2\", ...], \"occupation\": [\"value_1\", \"value_2\", ...], \"category\": [\"value_1\", \"value_2\", ...]}}</json>\n",
    "\n",
    "Note: \n",
    "* Ensure that the extracted values for the eligibility criteria are from the provided options only.\n",
    "\n",
    "Response:\"\"\"\n",
    "    prompt = PromptTemplate(\n",
    "        template=prompt_template, input_variables=[\"text\", \"current_types\"]\n",
    "    )\n",
    "    response = llm(prompt.format(text=web_page_text, current_types=field_to_types))\n",
    "    json_pattern = f\"(?<=<json>).*(?=</json>)\"\n",
    "    dict_string = re.search(json_pattern, response).group()\n",
    "    scheme_details = literal_eval(dict_string)\n",
    "    return scheme_details\n",
    "    \n",
    "\n",
    "def get_scheme_details_and_update_types(scheme_link):\n",
    "    web_page_text = read_web_page(scheme_link)\n",
    "    # update types if required\n",
    "    field_to_types = get_existing_types()\n",
    "    types_suggestions = get_types_suggestions(web_page_text, field_to_types)\n",
    "    is_confirmation_required = False\n",
    "    for _, types in field_to_types.items():\n",
    "        if len(types) > 0:\n",
    "            is_confirmation_required = True\n",
    "    if is_confirmation_required:\n",
    "        confirmation = input((\n",
    "            f\"Suggestions: {json.dumps(types_suggestions, indent=4)}\\n\\n\"\n",
    "            \"Do you want to accept(yes/no):\"\n",
    "        ))\n",
    "        if confirmation == \"yes\":\n",
    "           field_to_types = update_existing_types(types_suggestions)\n",
    "    return get_scheme_details(web_page_text, field_to_types)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils for Generating Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_questions_prompt():\n",
    "    question_template = \"\"\"You are a legal expert and are tasked to analyze text from a government scheme.\n",
    "\n",
    "text: {text}\n",
    "    \n",
    "Read the text very carefully and answer the following question: {question}\n",
    "\n",
    "Output Format: The output should only contain the answer to the question. For question related to \n",
    "scheme name only return the scheme name. For descriptive answers, use simple and coherent language and \n",
    "answer the question using paragraph format.\n",
    "\n",
    "Answer:\"\"\"\n",
    "    return PromptTemplate(template=question_template, input_variables=[\"text\", \"question\"])\n",
    "\n",
    "\n",
    "def get_format_summary_prompt():\n",
    "    format_summary_prompt_template = \"\"\"You need to format the following summary of a government document.\n",
    "summary: {text}\n",
    "    \n",
    "Output Format: The output should be in a text format. The section in the summary are: \n",
    "(Name of Scheme, Eligibility Criteria, Benefits of the Scheme, Steps to Avail, Source)\n",
    "There should be markdown heading for each sections.If some information is present in multiple \n",
    "section, only keep that information in the most relevant sections.\n",
    "\n",
    "Note: The summary should not have contain any double quotes (\").\n",
    "\n",
    "Formatted Summary:\"\"\"\n",
    "    return PromptTemplate(template=format_summary_prompt_template, input_variables=[\"text\"])\n",
    "\n",
    "\n",
    "def generate_summary(text, link):\n",
    "    summary = \"\"\n",
    "    llm = get_text_model()\n",
    "    questions = [\n",
    "        (\"Name\", \"What is the name of the government scheme?\"),\n",
    "        (\"Eligibility Criteria\", \"Are the any eligibility criteria, validity, conditions to avail the scheme?\"),\n",
    "        (\"Benefits\", \"What benefits does the government scheme provide?\"),\n",
    "        (\"Steps to Avail\", \"What are the steps to avail or apply for the government scheme?\")\n",
    "    ]\n",
    "\n",
    "    question_prompt = get_questions_prompt()\n",
    "    format_summary_prompt = get_format_summary_prompt()\n",
    "\n",
    "    for question in questions:\n",
    "        summary += (f\"{question[0]}: \" + llm(question_prompt.format(text=text, question=question[1])) + \"\\n\\n\\n\")\n",
    "    summary += (\"Source: \" + link)\n",
    "    \n",
    "    return llm(format_summary_prompt.format(text=summary))\n",
    "\n",
    "\n",
    "def translate_to_hindi(text):\n",
    "    prompt_template = \"\"\"Translate the following text to hindi language, \n",
    "while ensuring that there is no loss of information or changes in formatting.\n",
    "\n",
    "Note: The translated text should not have contain any double quotes (\").\n",
    "\n",
    "text: {text}\n",
    "    \n",
    "Translated Text:\"\"\"\n",
    "    prompt = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "    return llm(prompt.format(text=text))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for url in tqdm(tn_scheme_urls):\n",
    "    text = read_web_page(url)\n",
    "    try:\n",
    "        details = get_scheme_details_and_update_types(url)  \n",
    "        summary = generate_summary(text, url)\n",
    "        hindi_summary = translate_to_hindi(summary)\n",
    "        details[\"hindi_summary\"] = hindi_summary\n",
    "        details[\"summary\"] = summary          \n",
    "        details[\"text\"] = text\n",
    "        details[\"url\"] = url\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        details = {\"text\": text}\n",
    "        details[\"url\"] = url    \n",
    "    data.append(details)\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"new_database.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = \"\"\"File: women_tn_2.html, Response: <json>{\"gender\": [\"Female\"], \"occupation\": [\"None\"], \"category\": [\"None\"]}</json>\n",
    "File: women_tn_1.html, Response: <json>{\"gender\": [\"Female\"], \"occupation\": [\"None\"], \"category\": [\"None\"]}</json>\n",
    "File: sc_st_tn_2.html, Response: <json>{\"gender\": [\"None\"], \"occupation\": [\"None\"], \"category\": [\"SC\", \"ST\"]}</json>\n",
    "File: student_gj_3.html, Response: <json>{\"gender\": [\"None\"], \"occupation\": [\"Student\"], \"category\": [\"None\"]}</json>\n",
    "File: student_gj_1.html, Response: <json>{\"gender\": [\"Male\", \"Female\"], \"occupation\": [\"Student\"], \"category\": [\"None\"]}</json>\n",
    "File: students_tn_2.html, Response: <json>{\"gender\": [\"None\"], \"occupation\": [\"Student\"], \"category\": [\"None\"]}</json>\n",
    "File: famers_tn_3.html, Response: <json>{\"gender\": [\"None\"], \"occupation\": [\"Farmers\"], \"category\": [\"None\"]}</json>\n",
    "File: sc_st_tn_1.html, Response: <json>{\"gender\": [\"None\"], \"occupation\": [\"Student\"], \"category\": [\"SC\", \"ST\"]}</json>\n",
    "File: woment_tn_3.html, Response: <json>{\"gender\": [\"Female\"], \"occupation\": [\"None\"], \"category\": [\"None\"]}</json>\n",
    "File: students_gj_2.html, Response: <json>{\"gender\": [\"None\"], \"occupation\": [\"Student\"], \"category\": [\"None\"]}</json>\n",
    "File: sc_st_tn_3.html, Response: <json>{\"gender\": [\"None\"], \"occupation\": [\"Student\"], \"category\": [\"SC\", \"ST\"]}</json>\n",
    "File: famers_tn_2.html, Response: <json>{\"gender\": [\"None\"], \"occupation\": [\"Farmers\"], \"category\": [\"None\"]}</json>\n",
    "File: famers_tn_1.html, Response: <json>{\"gender\": [\"None\"], \"occupation\": [\"Farmers\"], \"category\": [\"None\"]}</json>\n",
    "File: students_tn_1.html, Response: <json>{\"gender\": [\"None\"], \"occupation\": [\"Farmers\", \"Student\"], \"category\": [\"None\"]}</json>\n",
    "File: students_tn_3.html, Response: <json>{\"gender\": [\"None\"], \"occupation\": [\"Student\"], \"category\": [\"None\"]}</json>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_link(html_content):\n",
    "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "    if \"gujarat\" in html_content:\n",
    "        tag = soup.find(\"a\", {\"title\": \"Skip to Main Content\"})\n",
    "        pattern = r\"https://sje.gujarat.gov.in/.{4}/schemes/\\d+\"\n",
    "        link =re.search(pattern, tag[\"href\"]).group()\n",
    "        return link\n",
    "    else:\n",
    "        tag = soup.find(\"a\", class_=\"increase\")\n",
    "        return tag[\"href\"][:-1]\n",
    "\n",
    "\n",
    "def parse_response(response):\n",
    "    file_pattern = r\"(?<=File: ).*html\"\n",
    "    file_name = re.search(file_pattern, response).group()\n",
    "    dict_pattern = f\"(?<=<json>).*(?=</json>)\"\n",
    "    dict_string = re.search(dict_pattern, response).group()\n",
    "    response = literal_eval(dict_string)\n",
    "    response[\"file_name\"] = file_name\n",
    "    return response\n",
    "\n",
    "\n",
    "data = []\n",
    "for response, path, doc in zip(responses.split(\"\\n\"), html_paths, docs):\n",
    "    file_content = Path(path).read_text()\n",
    "    page_link = get_page_link(file_content)\n",
    "    record = parse_response(response)\n",
    "    record[\"url\"] = page_link\n",
    "    record[\"text\"] = doc\n",
    "    data.append(record)\n",
    "    \n",
    "pd.DataFrame(data).to_csv(\"database.csv\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hindi_model(pat):\n",
    "    USER_ID = \"facebook\"\n",
    "    APP_ID = \"translation\"\n",
    "    MODEL_ID = \"translation-english-to-hindi-text\"\n",
    "    llm = Clarifai(pat=pat, user_id=USER_ID, app_id=APP_ID, model_id=MODEL_ID)\n",
    "    return llm\n",
    "\n",
    "def translate_to_hindi(text):\n",
    "    model = get_hindi_model(\"2e47a12333004eafbd898b21e5bc94cf\")\n",
    "    return model(text)\n",
    "\n",
    "df.loc[:, \"hindi_summary\"] = df.apply(lambda x: translate_to_hindi(x[\"Summary\"]), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eligibility_prompt_template = \"\"\"You are a legal expert and are tasked to identify if a user\n",
    "is eligible for a given government scheme.\n",
    "\n",
    "Government Scheme: {scheme}\n",
    "\n",
    "User Description: {description}\n",
    "User Gender: {gender}\n",
    "User Occupation: {occupation}\n",
    "User Category: {category}\n",
    "\n",
    "Based on the provided user information and the description of the government scheme, \n",
    "please assess whether the user is eligible for the scheme and respond with a 'Yes' or 'No' accordingly.\n",
    "\n",
    "Note: the response should only be a single word yes / no, nothing else.\n",
    "\n",
    "Response:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = get_text_model()\n",
    "def translate_to_hindi(text):\n",
    "    format_summary_prompt_template = \"\"\"Translate the following text to hindi language, while ensuring that there is no\n",
    "loss of information or changes in formatting.\n",
    "\n",
    "text: {text}\n",
    "    \n",
    "translated text:\"\"\"\n",
    "    prompt = PromptTemplate(template=format_summary_prompt_template, input_variables=[\"text\"])\n",
    "    return llm(prompt.format(text=text))\n",
    "\n",
    "df.loc[:, \"hindi_summary\"] = df.apply(lambda x: translate_to_hindi(x[\"Summary\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi_summaries = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    try:\n",
    "        summary = translate_to_hindi(row[\"Summary\"])\n",
    "        hindi_summaries.append(summary)\n",
    "    except Exception as e:\n",
    "        hindi_summaries.append(\"Error\")\n",
    "\n",
    "print(hindi_summaries)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
